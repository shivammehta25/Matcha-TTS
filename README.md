<div align="center">

# ğŸµ Matcha-TTS: æ¡ä»¶ä»˜ããƒ•ãƒ­ãƒ¼ãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚‹é«˜é€ŸTTSã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### [Shivam Mehta](https://www.kth.se/profile/smehta), [Ruibo Tu](https://www.kth.se/profile/ruibo), [Jonas Beskow](https://www.kth.se/profile/beskow), [Ã‰va SzÃ©kely](https://www.kth.se/profile/szekely), and [Gustav Eje Henter](https://people.kth.se/~ghe/)

[![python](https://img.shields.io/badge/-Python_3.10-blue?logo=python&logoColor=white)](https://www.python.org/downloads/release/python-3100/)
[![pytorch](https://img.shields.io/badge/PyTorch_2.0+-ee4c2c?logo=pytorch&logoColor=white)](https://pytorch.org/get-started/locally/)
[![lightning](https://img.shields.io/badge/-Lightning_2.0+-792ee5?logo=pytorchlightning&logoColor=white)](https://pytorchlightning.ai/)
[![hydra](https://img.shields.io/badge/Config-Hydra_1.3-89b8cd)](https://hydra.cc/)
[![black](https://img.shields.io/badge/Code%20Style-Black-black.svg?labelColor=gray)](https://black.readthedocs.io/en/stable/)
[![isort](https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336)](https://pycqa.github.io/isort/)

<p style="text-align: center;">
  <img src="https://shivammehta25.github.io/Matcha-TTS/images/logo.png" height="128"/>
</p>

</div>

> ã“ã‚Œã¯Matcha-TTSã®éå…¬å¼æ—¥æœ¬èªç‰¹åŒ–å‹ã‚³ãƒ¼ãƒ‰ã§ã™ã€‚
> ãªãŠã€æœ¬å®¶ã¨ã¯Attentionæ©Ÿæ§‹ãŒé•ã„ã¾ã™

ç§ãŸã¡ã¯ã€ODEã«åŸºã¥ãéŸ³å£°åˆæˆã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã«ã€[æ¡ä»¶ä»˜ããƒ•ãƒ­ãƒ¼ãƒãƒƒãƒãƒ³ã‚°](https://arxiv.org/abs/2210.02747) ([æ•´æµãƒ•ãƒ­ãƒ¼](https://arxiv.org/abs/2209.03003) ã«é¡ä¼¼)ã‚’ä½¿ç”¨ã™ã‚‹ã€éè‡ªå·±å›å¸°çš„ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«TTSã®æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹ğŸµæŠ¹èŒ¶TTSã‚’ææ¡ˆã—ã¾ã—ãŸã€‚
ä»¥ä¸‹ãŒåˆ©ç‚¹ã§ã™ã€‚

- ç¢ºç‡çš„ã§ã‚ã‚‹
- ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªãƒ¡ãƒ¢ãƒªãƒ•ãƒƒãƒˆãƒ—ãƒªãƒ³ãƒˆ
- éå¸¸ã«è‡ªç„¶ã«èã“ãˆã‚‹
- åˆæˆé€Ÿåº¦ãŒé€Ÿã„

è©³ç´°ã¯[ãƒ‡ãƒ¢ãƒšãƒ¼ã‚¸](https://shivammehta25.github.io/Matcha-TTS)ã¨[ICASSP 2024è«–æ–‡](https://arxiv.org/abs/2309.03199)ã‚’ã”è¦§ãã ã•ã„ã€‚

[è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«](https://drive.google.com/drive/folders/17C_gYgEHOxI5ZypcfE_k1piKCtyR0isJ?usp=sharing)ã¯CLIã¾ãŸã¯gradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹ã§è‡ªå‹•çš„ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ã€‚

ã¾ãŸã€[HuggingFace ğŸ¤— spaces](https://huggingface.co/spaces/shivammehta25/Matcha-TTS)ã§ãƒ–ãƒ©ã‚¦ã‚¶ä¸Šã§ğŸµMatcha-TTSã‚’è©¦ã™ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

## è§£èª¬å‹•ç”»

[![Watch the video](https://img.youtube.com/vi/xmvJkz3bqw0/hqdefault.jpg)](https://youtu.be/xmvJkz3bqw0)

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

1. ç’°å¢ƒã‚’ä½œã‚‹(ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

```
conda create -n matcha-tts python=3.10 -y
conda activate matcha-tts
```

2. Matcha TTSã‚’pipã¾ãŸã¯ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
pip install matcha-tts
```

ã‚½ãƒ¼ã‚¹ã‹ã‚‰

```bash
pip install git+https://github.com/tuna2134/Matcha-TTS-JP.git
cd Matcha-TTS-JP
pip install -e .
```

3. CLIã‚’å®Ÿè¡Œ / gradio app / jupyter notebook

```bash
# å¿…è¦ãªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
matcha-tts --text "<INPUT TEXT>"
```

```bash
matcha-tts-app
```

ã‚‚ã—ãã¯jupyter notebookã§`synthesis.ipynb`ã‚’é–‹ãã¾ã™ã€‚

### CLIå¼•æ•°

- ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸ãˆã¦ã®éŸ³å£°ç”Ÿæˆã¯ä»¥ä¸‹ã®é€šã‚Šã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

```bash
matcha-tts --text "<INPUT TEXT>"
```

- ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰éŸ³å£°ç”Ÿæˆã—ãŸã„å ´åˆã¯ä»¥ä¸‹ã®é€šã‚Šã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

```bash
matcha-tts --file <PATH TO FILE>
```

- ãƒãƒƒãƒã‚’åˆ©ç”¨ã—ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®éŸ³å£°ç”Ÿæˆã—ãŸã„å ´åˆã¯ä»¥ä¸‹ã®é€šã‚Šã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

```bash
matcha-tts --file <PATH TO FILE> --batched
```

è¿½åŠ ã®å¼•æ•°

- Speaking rate

```bash
matcha-tts --text "<INPUT TEXT>" --speaking_rate 1.0
```

- Sampling temperature

```bash
matcha-tts --text "<INPUT TEXT>" --temperature 0.667
```

- Euler ODE solver steps

```bash
matcha-tts --text "<INPUT TEXT>" --steps 10
```

## è‡ªåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹

JSUTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ©ç”¨ã—ã¦ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã—ã‚‡ã†ï¼

1. ã¾ãšJSUTã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€data/jsutã«é…ç½®ã—ã¦ãã ã•ã„ã€‚é ‘å¼µã£ã¦`train.txt`ã¨`val.txt`ã«åˆ†ã‘ã¦ãã ã•ã„ã€‚
â€»wavãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã¯20040hzã«ã™ã‚‹ã“ã¨ã‚’ãŠã™ã™ã‚ã—ã¾ã™ã€‚

2. Matcha-TTSã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¦ã€ç§»å‹•ã™ã‚‹ã€‚

```bash
git clone https://github.com/tuna2134/Matcha-TTS-JP.git
cd Matcha-TTS-JP
```

3. ã‚½ãƒ¼ã‚¹ã‹ã‚‰ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹

```bash
pip install -e .
```

4. `configs/data/hi-fi_jsut.yaml`ã‚’ç·¨é›†ã™ã‚‹ã€‚

```yaml
train_filelist_path: data/train.txt
valid_filelist_path: data/val.txt
```

5. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šã®yamlãƒ•ã‚¡ã‚¤ãƒ«ã§æ­£è¦åŒ–çµ±è¨ˆã‚’ç”Ÿæˆã™ã‚‹ã€‚

```bash
matcha-data-stats -i jsut.yaml
# Output:
#{'mel_mean': -5.53662231756592, 'mel_std': 2.1161014277038574}
```

ã“ã‚Œã‚‰ã®å€¤ã‚’ `configs/data/hi-fi_jsut.yaml` ã® `data_statistics` ã‚­ãƒ¼ã§æ›´æ–°ã™ã‚‹ã€‚

```bash
data_statistics:  # Computed for ljspeech dataset
  mel_mean: -5.536622
  mel_std: 2.116101
```

6. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

```bash
python matcha/train.py experiment=jsut
```

7. ã‚«ã‚¹ã‚¿ãƒ ã•ã‚ŒãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã§éŸ³å£°ã‚’ç”Ÿæˆã™ã‚‹ã€‚

```bash
matcha-tts --text "<INPUT TEXT>" --checkpoint_path <PATH TO CHECKPOINT>
```

## ONNXã®ã‚µãƒãƒ¼ãƒˆ

> ONNXã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã¨æ¨è«–ã‚µãƒãƒ¼ãƒˆã‚’å®Ÿè£…ã—ã¦ãã‚ŒãŸ[@mush42](https://github.com/mush42)ã«æ„Ÿè¬ã—ã¾ã™ã€‚

æŠ¹èŒ¶ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’[ONNX](https://onnx.ai/)ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã€ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã•ã‚ŒãŸONNXã‚°ãƒ©ãƒ•ã«å¯¾ã—ã¦æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

### ONNXã¸å¤‰æ›

ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ONNXã«å¤‰æ›ã™ã‚‹å‰ã«ä»¥ä¸‹ã®é€šã‚Šã«ONNXã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚

```bash
pip install onnx
```

ãã®å¾Œã«ä»¥ä¸‹ã®é€šã‚Šã«å®Ÿè¡Œã—ã¦ãã ã•ã„

```bash
python3 -m matcha.onnx.export matcha.ckpt model.onnx --n-timesteps 5
```

(ã‚ªãƒ—ã‚·ãƒ§ãƒ³) ONNXå¤‰æ›å™¨ã¯**vocoder-name**ã¨**vocoder-checkpoint**å¼•æ•°ã‚’å—ã‘ä»˜ã‘ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ãŸã‚°ãƒ©ãƒ•ã«ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ã‚’çµ„ã¿è¾¼ã¿ã€1å›ã®å®Ÿè¡Œã§æ³¢å½¢ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼ˆã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®TTSã‚·ã‚¹ãƒ†ãƒ ã¨åŒæ§˜ï¼‰ã€‚

**Note** `n_timesteps`ã¯ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ã§ã¯ãªããƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦æ‰±ã‚ã‚Œã¾ã™ã€‚ã¤ã¾ã‚Šã€(æ¨è«–æ™‚ã§ã¯ãªã)ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ™‚ã«æŒ‡å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚æŒ‡å®šã—ãªã„å ´åˆ`n_timesteps`ã¯**5**ã«è¨­å®šã•ã‚Œã¾ã™ã€‚

**Important**: å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯ `scaled_product_attention` æ¼”ç®—å­ãŒã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã§ããªã„ãŸã‚ã€ä»Šã®ã¨ã“ã‚ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã«ã¯ torch>=2.1.0 ãŒå¿…è¦ã§ã™ã€‚æœ€çµ‚ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã‚‹ã¾ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ãŸã„äººã¯ãƒ—ãƒ¬ãƒªãƒªãƒ¼ã‚¹ã¨ã—ã¦torch>=2.1.0ã‚’æ‰‹å‹•ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

### ONNXæ¨è«–

ã‚¨ã‚­ã‚¹ãƒãƒ¼ãƒˆã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’æ¨è«–ã™ã‚‹å‰ã«`onnxruntime`ä»¥ä¸‹ã®é€šã‚Šã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚

```bash
pip install onnxruntime
pip install onnxruntime-gpu  # GPUæ¨è«–ã™ã‚‹å ´åˆ
```

ãã®å¾Œã«ä»¥ä¸‹ã®é€šã‚Šã«å®Ÿè¡Œã—ã¦æ¨è«–ã—ã¦ãã ã•ã„ã€‚

```bash
python3 -m matcha.onnx.infer model.onnx --text "hey" --output-dir ./outputs
```

éŸ³å£°åˆæˆã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚‚ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã§ãã¾ã™ã€‚

```bash
python3 -m matcha.onnx.infer model.onnx --text "hey" --output-dir ./outputs --temperature 0.4 --speaking_rate 0.9 --spk 0
```

**GPU**ä¸Šã§æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€å¿…ãš**onnxruntime-gpu**ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ã€æ¨è«–ã‚³ãƒãƒ³ãƒ‰ã«--gpu`ã‚’æ¸¡ã—ã¦ãã ã•ã„ï¼š

```bash
python3 -m matcha.onnx.infer model.onnx --text "hey" --output-dir ./outputs --gpu
```

Matchaã ã‘ã‚’ONNXã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ãŸå ´åˆã¯ã€mel-spectrogramã‚’ã‚°ãƒ©ãƒ•ã¨`numpy`é…åˆ—ã¨ã—ã¦å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«æ›¸ãå‡ºã—ã¾ã™ã€‚
ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ãŸã‚°ãƒ©ãƒ•ã«ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ã‚’åŸ‹ã‚è¾¼ã‚“ã å ´åˆã€`.wav`ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«æ›¸ãå‡ºã—ã¾ã™ã€‚

Matchaã ã‘ã‚’ONNXã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã€å®Œå…¨ãªTTSãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã—ãŸã„å ´åˆã¯ã€`ONNX`ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ãƒ¢ãƒ‡ãƒ«ã¸ã®ãƒ‘ã‚¹ã‚’æ¸¡ã™ã“ã¨ãŒã§ãã¾ã™:

```bash
python3 -m matcha.onnx.infer model.onnx --text "hey" --output-dir ./outputs --vocoder hifigan.small.onnx
```

outputãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«wavãƒ•ã‚¡ã‚¤ãƒ«ãŒæ›¸ãè¾¼ã¾ã‚Œã¾ã™ã€‚

## Extract phoneme alignments from Matcha-TTS

If the dataset is structured as

```bash
data/
â””â”€â”€ LJSpeech-1.1
    â”œâ”€â”€ metadata.csv
    â”œâ”€â”€ README
    â”œâ”€â”€ test.txt
    â”œâ”€â”€ train.txt
    â”œâ”€â”€ val.txt
    â””â”€â”€ wavs
```
Then you can extract the phoneme level alignments from a Trained Matcha-TTS model using:
```bash
python  matcha/utils/get_durations_from_trained_model.py -i dataset_yaml -c <checkpoint>
```
Example:
```bash
python  matcha/utils/get_durations_from_trained_model.py -i ljspeech.yaml -c matcha_ljspeech.ckpt
```
or simply:
```bash
matcha-tts-get-durations -i ljspeech.yaml -c matcha_ljspeech.ckpt
```
---
## Train using extracted alignments

In the datasetconfig turn on load duration.
Example: `ljspeech.yaml`
```
load_durations: True
```
or see an examples in configs/experiment/ljspeech_from_durations.yaml


## å¼•ç”¨å…ƒ

ç§ãŸã¡ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€ã‚ã‚‹ã„ã¯ã“ã®ç ”ç©¶ãŒå½¹ã«ç«‹ã¤ã¨æ€ã‚ã‚Œã‚‹å ´åˆã¯ã€ç§ãŸã¡ã®è«–æ–‡ã‚’å¼•ç”¨ã—ã¦ãã ã•ã„ã€‚

```text
@inproceedings{mehta2024matcha,
  title={Matcha-{TTS}: A fast {TTS} architecture with conditional flow matching},
  author={Mehta, Shivam and Tu, Ruibo and Beskow, Jonas and Sz{\'e}kely, {\'E}va and Henter, Gustav Eje},
  booktitle={Proc. ICASSP},
  year={2024}
}
```

## è¬è¾

Since this code uses [Lightning-Hydra-Template](https://github.com/ashleve/lightning-hydra-template), you have all the powers that come with it.

Other source code we would like to acknowledge:

- [Coqui-TTS](https://github.com/coqui-ai/TTS/tree/dev): For helping me figure out how to make cython binaries pip installable and encouragement
- [Hugging Face Diffusers](https://huggingface.co/): For their awesome diffusers library and its components
- [Grad-TTS](https://github.com/huawei-noah/Speech-Backbones/tree/main/Grad-TTS): For the monotonic alignment search source code
- [torchdyn](https://github.com/DiffEqML/torchdyn): Useful for trying other ODE solvers during research and development
- [labml.ai](https://nn.labml.ai/transformers/rope/index.html): For the RoPE implementation
